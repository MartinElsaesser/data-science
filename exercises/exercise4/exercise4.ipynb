{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb259e13",
   "metadata": {},
   "source": [
    "### Teilaufgabe 1\n",
    "\n",
    "Wir befinden uns in der Situation, das Ergebnis eines Entscheidungsbaums (im Falle einer Klassifikation) bewerten zu wollen.\n",
    "\n",
    "Schreiben Sie eine Funktion, die den Vorhersage-Vektor und den {0,1}-wertigen Labelvektor als Argumente bekommt und die die Größen \"Anzahl True Positive\", \"Anzahl False Positive\", \"Anzahl True Negative\", \"Anzahl False Negative\" zurückgibt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f83b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tree_scores(y_label, y_pred):\n",
    "\tTP = np.sum((y_label == 1) & (y_pred == 1))\n",
    "\tFP = np.sum((y_label == 0) & (y_pred == 1))\n",
    "\tTN = np.sum((y_label == 0) & (y_pred == 0))\n",
    "\tFN = np.sum((y_label == 1) & (y_pred == 0))\n",
    "\treturn TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c08451e",
   "metadata": {},
   "source": [
    "### Teilaufgabe 2\n",
    "\n",
    "Schreiben Sie eine Funktion, die aus den unter 1. genannten Rückgabewerten die Accuracy berechnet.\n",
    "\n",
    "Recherchieren Sie die Größen Sensitivität, Spezifität, Precision, Recall und lassen Sie diese Größen ebenfalls berechnen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79fb1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tree_accuracy_score(TP, FP, TN, FN):\n",
    "\treturn (TP + TN) / (TP + FP + TN + FN)\n",
    "\n",
    "\n",
    "def compute_tree_sensitivity_score(TP, FP, TN, FN):\n",
    "\treturn TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "\n",
    "def compute_tree_specificity_score(TP, FP, TN, FN):\n",
    "\treturn TN / (TN + FP) if (TN + FP) > 0 else 0.0\n",
    "\n",
    "\n",
    "def compute_tree_precision_score(TP, FP, TN, FN):\n",
    "\treturn TP / (TP + FP) if (TP + FP) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff626cfa",
   "metadata": {},
   "source": [
    "[specificity and sensitivity in data science](https://medium.com/trusted-data-science-haleon/specificity-and-sensitivity-in-data-science-9d0c19b102ab)\n",
    "\n",
    "#### Sensitivität/Recall\n",
    "Sensitivität ist ein anderes Wort für Recall beschreibt den Prozent Satz der true positives zu allen Positiven (TP + FN).\n",
    "\n",
    "Sensitivität ist besonders im medizinischen Kontext sehr wichtig.\n",
    "Denn eine hohe Sensitivität sagt aus, dass wenige positiv Fälle falsch als negativ klassifiziert werden.\n",
    "Sprich von Patienten die Krebs haben, wird bei nahe zu allen dieser Krebs erkannt.\n",
    "\n",
    "#### Spezifität\n",
    "Spezifität misst den Prozent Satz der true negatives zu allen Negativen (TN + FP).\n",
    "\n",
    "Eine hohe Spezifität sagt aus, dass wenige negative Fälle falsch als positiv klassifiziert werden.\n",
    "Sprich von allen Patienten ohne Krebs, wird bei nahe zu allen festgestellt, dass sie gesund sind.\n",
    "\n",
    "#### Precision\n",
    "Precision misst den Prozent Satz der true positives zu allen als positiv erkannten (TP + FP).\n",
    "\n",
    "Eine hohe precision sagt aus, wie gut das Modell darin ist true positives zu erkennen.\n",
    "Diese Metrik wird verwendet, falls false positives wichtiger sind als false negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae65d8e",
   "metadata": {},
   "source": [
    "### Teilaufgabe 3\n",
    "\n",
    "Wir betrachten nun die Situation, in dem ein Test auf 100 Patienten angewendet wird, von denen 99 gesund und einer krank ist.\n",
    "\n",
    "Der Test zeigt für alle 100 Patienten \"gesund\" an. Berechnen Sie die unter 2. genannten Metriken.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3754dfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 0, FP: 0, TN: 99, FN: 1\n",
      "accuracy: 0.99, sensitivity: 0.00, specificity: 1.00, precision: 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# healthy: 1, sick: 0\n",
    "y_label = np.repeat([0,1], [99,1])\n",
    "y_pred = np.repeat([0,1], [100,0])\n",
    "\n",
    "TP, FP, TN, FN = compute_tree_scores(y_label, y_pred)\n",
    "accuracy = compute_tree_accuracy_score(TP, FP, TN, FN)\n",
    "sensitivity = compute_tree_sensitivity_score(TP, FP, TN, FN)\n",
    "specificity = compute_tree_specificity_score(TP, FP, TN, FN)\n",
    "precision = compute_tree_precision_score(TP, FP, TN, FN)\n",
    "print(f\"TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\")\n",
    "print(f\"accuracy: {accuracy:.2f}, sensitivity: {sensitivity:.2f}, specificity: {specificity:.2f}, precision: {precision:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9e299",
   "metadata": {},
   "source": [
    "### Teilaufgabe 4\n",
    "\n",
    "Arbeiten Sie das Tutorial https://mlu-explain.github.io/precision-recall/ durch.\n",
    "\n",
    "Was ist unter Precision-Recall-Tradeoff zu verstehen? Versuchen Sie, im Slider im Tutorial Precision und Recall über 0.6 zu bringen und notieren Sie den verwendeten Threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949eafb4",
   "metadata": {},
   "source": [
    "Steigt die Precision, fällt der Recall Wert und vice-versa. Threshold Wert etwa 0.52\n",
    "\n",
    "|                  | Predicted: Positiv | Predicted: Negative |\n",
    "|------------------|--------------------|---------------------|\n",
    "| Actual: Positive | TP: 6              | FN: 2               |\n",
    "| Actual: Negative | FP: 4              | TN: 23              |\n",
    "\n",
    "\n",
    "\n",
    "> Take our cancer example: designing a model with high recall will identify most people that have cancer (true positives), saving their lives, but at the cost of misdiagnosing healthy individuals as having cancer (false positives), subjecting them to expensive and dangerous treatments like chemotherapy. On the other hand, designing a model for precision yields confident diagnoses (i.e. someone predicted as having cancer very likely does have cancer), but at the cost of failing to identify everyone who has the disease (false negatives), resulting in potentially fatal consequences for those left undiagnosed. (Because False Negatives result in death, our classification threshold would likely be set to optimize recall over precision)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b545a4b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
